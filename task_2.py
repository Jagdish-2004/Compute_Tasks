# -*- coding: utf-8 -*-
"""Task_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bb3KEyvZxZw6ZpKH33zzS1TAwXCmeIlJ
"""

import numpy as np
import pandas as pd
import matplotlib as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle

"""#Importing Data"""

df=pd.read_csv('/content/drive/MyDrive/automobile_data.csv')

"""# Analyzing the Data"""

df.head()

df.info()

df.describe()

df.columns

"""**Checking Null Values**"""

df.isnull().sum()

df.duplicated().sum()

df['normalized-losses']

"""Handling missing values"""

df.replace('?',np.nan,inplace=True)#Replacing '?' with nan so we get the missing values

df.head()

df.isna().sum()

df['normalized-losses']=df['normalized-losses'].astype(float)
df['normalized-losses'].fillna(df['normalized-losses'].mean(),inplace=True)

df['bore']=df['bore'].astype(float)
df['bore'].fillna(df['bore'].mean(),inplace=True)

df['stroke']=df['stroke'].astype(float)
df['stroke'].fillna(df['stroke'].mean(),inplace=True)

df['horsepower']=df['horsepower'].astype(float)
df['horsepower'].fillna(df['horsepower'].mean(),inplace=True)

df['peak-rpm']=df['peak-rpm'].astype(float)
df['peak-rpm'].fillna(df['peak-rpm'].mean(),inplace=True)

df['price']=df['price'].astype(float)
df['price'].fillna(df['price'].mean(),inplace=True)

df['num-of-doors'].value_counts()

df['num-of-doors']=df['num-of-doors'].fillna('four')

df.isna().sum()

"""# Visualizing Data

"""

sns.heatmap(df.corr(numeric_only=True), annot=True, fmt='.1f', cmap='coolwarm').set(title='Correlation Heatmap')

"""Gives relation of each column with respect to other column"""

df.columns

sns.histplot(df['price'],color='blue')

"""Tells the frequency of price"""

sns.boxplot(data=df,x='fuel-type',y='price',patch_artist=True)

"""Shows the distribution of price with respect to fuel type"""

sns.scatterplot(data=df,x='horsepower',y='price',color='red')

"""Shows how price varies with horsepower"""

sns.lineplot(data=df,x='horsepower',y='price',color='green')

sns.lineplot(data=df,x='symboling',y='price',color='green')

sns.barplot(data=df,x='body-style',y='price',color='red')

"""Tells Price Distribution with respect to body style"""

df.to_csv('cleaned_data.csv',index=False)

"""# Applying Principal Component Analysis

Selecting only Numeric datatypes for PCA
"""

numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
df_numeric= df[numeric_columns]

"""Standardrizing the dataset"""

scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_numeric)

pca = PCA().fit(df_scaled)

variance = np.cumsum(pca.explained_variance_ratio_)#Tells the ratio of each column contributing to pc
variance

n_components_optimal = np.argmax(variance >= 0.90) + 1
n_components_optimal

pca_optimal=PCA(n_components=n_components_optimal)
df_pca=pca_optimal.fit_transform(df_scaled)
df_pca

"""# Splitting the Data"""

X = df_pca  # PCA features
y = df['price']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)#Splitting the data into 80-20 ratio

"""Initializing Linear Model"""

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)#Making Prediction
y_pred

mae = mean_absolute_error(y_test, y_pred)#Calculating Mean Absolute Error
mae

mse = mean_squared_error(y_test, y_pred)#Calculating Mean Square Error
mse

rmse = np.sqrt(mse)#Calculating Root Mean Square Error
rmse

r2 = r2_score(y_test, y_pred)#Calculating R^2
r2

pickle.dump(lr_model,open('/content/drive/MyDrive/model.pkl','wb'))